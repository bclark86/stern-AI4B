---
title: "Final Project"
author: "Bryan Clark & Vamsi Ponnapalli"
date: "12/10/2020"
output:
  pdf_document:
    latex_engine: xelatex
    df_print: kable
    toc: true
    toc_depth: 2
    highlight: monochrome
---

```{r setup, include=FALSE}
# customize output options 
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE,
                      fig.width = 6, fig.asp = 0.618, out.width = "70%", 
                      fig.align = "center")

# time code chunks
knitr::knit_hooks$set(timeit = local({
  now = NULL
  function(before, options) {
    if (before) {
      now <<- Sys.time()
    } else {
      res = difftime(Sys.time(), now)
      now <<- NULL
      # use options$label if you want the chunk label as well
      paste('Time to execute this code chunk:', as.character(round(res, 0)), 's')
    }
  }})
)

# python interface
library(reticulate)
use_miniconda("dl", required = T)
```

# Overview

In this term project, you will deploy Deep Learning models to build a classification model using RapidMiner to predict the sentiment of consumers towards US airlines based on their reviews expressed in the form of tweets. If you strongly prefer to use some other DL-based software/frameworks instead of RapidMiner, such as TensorFlow or PyTorch, let me know before starting the work. This is a group project, and you should work on it in the groups that you have formed already.

## Python Libraries

```{python}
# fetch data
import requests
from io import StringIO

# core
import numpy as np
import pandas as pd

# preprocessing
from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold

# baseline algorithms
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier

# deep learning
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, BatchNormalization, Dropout
from tensorflow.keras.losses import mean_absolute_error as tf_mae
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping

# evaluation
from sklearn.model_selection import cross_validate
from sklearn.metrics import mean_absolute_error as skl_mae
```

# 1. Fetch Data

The data is provided to you in two versions:

1. The original version of the tweets (and their sentiments) is located at https://drive.google.com/file/d/1atyRH5Yz7TU-2ziyZknfd7ib2LLwYeuv/view?usp=sharing. 

2. The preprocessed version of the tweets is located at https://drive.google.com/file/d/1c96crlNZr7XiF3-9lmZ1nEJaY3MHTTz5/view?usp=sharing, where text preprocessing and pre-training of the text embeddings of the tweets using autoencoders have already been done to make your life simpler. This preprocessed version contains the sentiments about the tweets in column 1 of the spreadsheet (either positive (1) or negative (0)) and the 8-dimenisonal pre-trained embeddings of the tweets (in columns 2 – 9 of the spreadsheet).

I recommend that you use the preprocessed version of the tweets since it will save you a lot of preprocessing work to build these embeddings that is non-trivial. However, if you like challenges, you can do preprocessing and building the embeddings using autoencoders yourself and, therefore, work directly with the “raw” tweets. As a “reward” for this extra work, you will be awarded 10 extra points (the max score of this project is 100) if you preprocess tweets yourself.

```{python}
# url of dataset
google_drive_file_url = 'https://drivesds.google.com/file/d/' \
    + '1c96crlNZr7XiF3-9lmZ1nEJaY3MHTTz5/view?usp=sharing'

def fetch_google_drive_csv(google_drive_file_url):

    file_id = google_drive_file_url.split('/')[-2]
    download_url = 'https://drive.google.com/uc?export=download&id=' + file_id
    url = requests.get(download_url)
    csv_raw = StringIO(url.text)
    return pd.read_csv(csv_raw)

data = fetch_google_drive_csv(google_drive_file_url)

data.head()
```

```{python}
data.info()
```
# 2. Preprocess Data

Your task is to predict the score of the sentiment (positive or negative) between 0 and 1 based on the embeddings of the tweets specified in columns 2 – 9 of the pre-possessed spreadsheet (or the original tweets if you decided to work with the raw tweeting data). To evaluate the performance of your model, please split the dataset into the train set and the test set in the 0.8:0.2 ratio and use cross-validation to calculate the prediction performance.

## 2.1 Train/Test Split

```{python}
target = 'sentiment'

X_train, X_test, y_train, y_test = train_test_split(
    data.drop(target, axis=1), # predictors
    data[target], # target
    test_size=0.2,
    random_state=90
)
```

```{python}
X_train.shape
```
```{python}
X_test.shape
```

## 2.2 Cross-Validation

### 2.2.1 Cross-Validation Splits

```{python}
cv_splits = KFold(n_splits=5, random_state=90, shuffle=True)

fold_num = 1
for train, test in cv_splits.split(X_train, y_train):
    print(f'Fold #{fold_num}: Train shape: {X_train.iloc[train].shape},',
          f'Test shape: {X_train.iloc[test].shape}')
    fold_num += 1

```
### 2.2.2 Keras Cross-Validation Wrapper

```{python}
def cross_val_score_keras(X_train, y_train, cv_spliter, model, batch_size, num_epochs):
    
    # model configuration
    loss_function = tf_mae
    optimizer = Adam()
    callback = EarlyStopping(monitor='loss', patience=10)
    
    # cross-validation scores
    cv_results = list()

    # K-fold Cross Validation model evaluation
    for train, test in cv_spliter.split(X_train, y_train):

        # compitle the model
        model.compile(loss=loss_function,
                      optimizer=optimizer)

        # fit data to model
        history = model.fit(X_train.iloc[train], y_train.iloc[train],
                            batch_size=batch_size,
                            epochs=num_epochs,
                            callbacks=[callback],
                            verbose=0)

        # generate generalization metrics
        score = model.evaluate(X_train.iloc[test], y_train.iloc[test], verbose=0)
        cv_results.append(score)
        
    return np.array(cv_results)
```


# 3. Neural Networks

You can use any neural network model you like for this classification task. In particular, you may start with a simple single fully connected network as a “baseline” and then try to use more complex models, including CNN and RNN based models, to achieve better performance results than this simple baseline model. Your goal is to reach the mean absolute error of at least 0.48, which should not be too difficult. If you want to be more ambitious, you can try to reach the mean absolute error of 0.47 (medium difficulty), or even 0.46 (this is difficult). The higher accuracy you get, the more points you will be awarded.

In addition to the simple NN baseline mentioned above, you should also build another basic baseline, such as a logistic regression model (similar to the one we used in the RapidMiner Lab done in the class) and compare the performance results of your DL-based model with that baseline. The expectation is that the more sophisticated DL-model should outperform simple baselines.

## 3.1 Baseline Model Performance

### 3.1.1 Logistic Regression

```{python, timeit = TRUE}
model_lr = LogisticRegression()
cv_results_lr = cross_validate(
    model_lr,
    X_train,
    y_train,
    scoring='neg_mean_absolute_error',
    cv=cv_splits
)
cv_lr_mu = -cv_results_lr['test_score'].mean()
cv_lr_sd = cv_results_lr['test_score'].std()

print(f'Logistic Regression MAE: {cv_lr_mu:.4f} +/- {cv_lr_sd:.4f}\n')
```

### 3.1.2 Random Forest

```{python, timeit = TRUE}
model_rf = RandomForestClassifier(n_estimators=500)
cv_results_rf = cross_validate(
    model_rf,
    X_train,
    y_train,
    scoring='neg_mean_absolute_error',
    cv=cv_splits
)
cv_rf_mu = -cv_results_rf['test_score'].mean()
cv_rf_sd = cv_results_rf['test_score'].std()

print(f'Random Forest MAE: {cv_rf_mu:.4f} +/- {cv_rf_sd:.4f}\n')
```

### 3.1.3 Simple Neural Network

```{python, timeit = TRUE}
# define the model architecture
model_nn_0 = Sequential([
    Dense(32, activation='relu', input_dim=8),
    Dense(1, activation='sigmoid')
])

# cross-validation
cv_results_nn_0 = cross_val_score_keras(
    X_train, y_train,
    cv_splits,
    model_nn_0,
    batch_size=50,
    num_epochs=100
)

# summary statistics
cv_nn_0_mu = cv_results_nn_0.mean()
cv_nn_0_sd = cv_results_nn_0.std()
print(f'Simlpe NN Baseline Model #0 MAE: {cv_nn_0_mu:.4f} +/- {cv_nn_0_sd:.4f}\n')
```

```{python}
# model paramters
batch_size = 250
num_epochs = 100
loss_function = tf_mae
optimizer = Adam()
callback = EarlyStopping(monitor='loss', patience=10)

# architecture
model_nn_0 = Sequential([
    Dense(32, activation='relu', input_dim=8),
    Dense(1, activation='sigmoid')
])

# compitle the model
model_nn_0.compile(loss=loss_function,
                   optimizer=optimizer)

# fit data to model
history_nn0 = model_nn_0.fit(X_train, y_train,
                             batch_size=batch_size,
                             epochs=num_epochs,
                             callbacks=[callback],
                             verbose=0)
```


## 3.2 Deep Learning

### 3.2.1 DL Model #1

```{python, timeit = TRUE}
# define the model architecture
model_nn_1 = Sequential([
    Dense(8, activation='relu', input_dim=8),
    Dense(8, activation='relu'),
    Dense(8, activation='relu'),
    Dense(8, activation='relu'),
    Dense(8, activation='relu'),
    Dense(8, activation='relu'),
    Dense(8, activation='relu'),
    Dense(8, activation='relu'),
    Dense(1, activation='sigmoid')
])

# cross-validation
cv_results_nn_1 = cross_val_score_keras(
    X_train, y_train,
    cv_splits,
    model_nn_1,
    batch_size=250,
    num_epochs=100
)

# summary statistics
cv_nn_1_mu = cv_results_nn_1.mean()
cv_nn_1_sd = cv_results_nn_1.std()
print(f'Deep Learning Model #1 MAE: {cv_nn_1_mu:.4f} +/- {cv_nn_1_sd:.4f}\n')
```

```{python  timeit = TRUE}
# model paramters
batch_size = 250
num_epochs = 100
loss_function = tf_mae
optimizer = Adam()
callback = EarlyStopping(monitor='loss', patience=10)

# architecture
model_nn_1 = Sequential([
    Dense(8, activation='relu', input_dim=8),
    Dense(8, activation='relu'),
    Dense(8, activation='relu'),
    Dense(8, activation='relu'),
    Dense(8, activation='relu'),
    Dense(8, activation='relu'),
    Dense(8, activation='relu'),
    Dense(8, activation='relu'),
    Dense(1, activation='sigmoid')
])

# compitle the model
model_nn_1.compile(loss=loss_function,
                   optimizer=optimizer)

# fit data to model
history_nn1 = model_nn_1.fit(X_train, y_train,
                             batch_size=batch_size,
                             epochs=num_epochs,
                             callbacks=[callback],
                             verbose=0)
```

### 3.2.2 DL Model #2

```{python  timeit = TRUE}
# define the model architecture
model_nn_2 = Sequential([
    Dense(64, activation='relu', input_dim=8),
    BatchNormalization(),
    Dense(32, activation='relu'),
    BatchNormalization(),
    Dense(16, activation='relu'),
    Dense(1, activation='sigmoid')
])

# cross-validation
cv_results_nn_2 = cross_val_score_keras(
    X_train, y_train,
    cv_splits,
    model_nn_2,
    batch_size=500,
    num_epochs=100
)

# summary statistics
cv_nn_2_mu = cv_results_nn_2.mean()
cv_nn_2_sd = cv_results_nn_2.std()
print(f'Deep Learning Model #1 MAE: {cv_nn_2_mu:.4f} +/- {cv_nn_2_sd:.4f}\n')
```

```{python  timeit = TRUE}
# model paramters
batch_size = 250
num_epochs = 100
loss_function = tf_mae
optimizer = Adam()
callback = EarlyStopping(monitor='loss', patience=10)

# compitle the model
model_nn_2.compile(loss=loss_function,
                   optimizer=optimizer)

# fit data to model
history_nn2 = model_nn_2.fit(X_train, y_train,
                             batch_size=batch_size,
                             epochs=num_epochs,
                             callbacks=[callback],
                             verbose=0)
```

# 4. Evaluation

After you build your neural network, apply the trained deep learning model to the test set and evaluate its performance using the accuracy measures.

```{python}
# refit baseline models with full data and predict holdout data
_ = model_lr.fit(X_train, y_train)
preds_lr = model_lr.predict(X_test)

_ = model_rf.fit(X_train, y_train)
preds_rf = model_rf.predict(X_test)

# predict test test for NN models
preds_nn_0 = model_nn_0.predict(X_test).reshape(-1)
preds_nn_1 = model_nn_1.predict(X_test).reshape(-1)
preds_nn_2 = model_nn_2.predict(X_test).reshape(-1)

# evaluation of test predictions
mae_test_lr = skl_mae(y_test, preds_lr)
mae_test_rf = skl_mae(y_test, preds_rf)
mae_test_nn_0 = skl_mae(y_test, preds_nn_0)
mae_test_nn_1 = skl_mae(y_test, preds_nn_1)
mae_test_nn_2 = skl_mae(y_test, preds_nn_2)

test_results_df = pd.DataFrame({
    'Model': ['logistic regression', 'random forest', 'simple NN', 'DL #1', 'DL #2'],
    'MAE': [mae_test_lr, mae_test_rf, mae_test_nn_0, mae_test_nn_1, mae_test_nn_2]
}).sort_values('MAE').reset_index(drop=True)

test_results_df
```

