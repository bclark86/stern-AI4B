{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "In this term project, you will deploy Deep Learning models to build a classification model using RapidMiner to predict the sentiment of consumers towards US airlines based on their reviews expressed in the form of tweets. If you strongly prefer to use some other DL-based software/frameworks instead of RapidMiner, such as TensorFlow or PyTorch, let me know before starting the work. This is a group project, and you should work on it in the groups that you have formed already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch data\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "# core\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# baseline algorithms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# deep learning\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.losses import mean_absolute_error as tf_mae\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# evaluation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import mean_absolute_error as skl_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Fetch Data\n",
    "\n",
    "The data is provided to you in two versions: \n",
    "\n",
    "1. The original version of the tweets (and their sentiments) is located at https://drive.google.com/file/d/1atyRH5Yz7TU-2ziyZknfd7ib2LLwYeuv/view?usp=sharing\n",
    "2. The preprocessed version of the tweets is located at https://drive.google.com/file/d/1c96crlNZr7XiF3-9lmZ1nEJaY3MHTTz5/view?usp=sharing, where text preprocessing and pre-training of the text embeddings of the tweets using autoencoders have already been done to make your life simpler. This preprocessed version contains the sentiments about the tweets in column 1 of the spreadsheet (either positive (1) or negative (0)) and the 8-dimenisonal pre-trained embeddings of the tweets (in columns 2 – 9 of the spreadsheet).\n",
    "\n",
    "I recommend that you use the preprocessed version of the tweets since it will save you a lot of preprocessing work to build these embeddings that is non-trivial. However, if you like challenges, you can do preprocessing and building the embeddings using autoencoders yourself and, therefore, work directly with the “raw” tweets. As a “reward” for this extra work, you will be awarded 10 extra points (the max score of this project is 100) if you preprocess tweets yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url of dataset\n",
    "google_drive_file_url = 'https://drivesds.google.com/file/d/1c96crlNZr7XiF3-9lmZ1nEJaY3MHTTz5/view?usp=sharing'\n",
    "\n",
    "def fetch_google_drive_csv(google_drive_file_url):\n",
    "\n",
    "    file_id = google_drive_file_url.split('/')[-2]\n",
    "    download_url = 'https://drive.google.com/uc?export=download&id=' + file_id\n",
    "    url = requests.get(download_url)\n",
    "    csv_raw = StringIO(url.text)\n",
    "    return pd.read_csv(csv_raw)\n",
    "\n",
    "data = fetch_google_drive_csv(google_drive_file_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>dimension1</th>\n",
       "      <th>dimension2</th>\n",
       "      <th>dimension3</th>\n",
       "      <th>dimension4</th>\n",
       "      <th>dimension5</th>\n",
       "      <th>dimension6</th>\n",
       "      <th>dimension7</th>\n",
       "      <th>dimension8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.400418</td>\n",
       "      <td>0.293417</td>\n",
       "      <td>-0.572702</td>\n",
       "      <td>0.125659</td>\n",
       "      <td>0.471714</td>\n",
       "      <td>-0.034476</td>\n",
       "      <td>0.042176</td>\n",
       "      <td>-0.429317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.454608</td>\n",
       "      <td>-0.194998</td>\n",
       "      <td>-0.497063</td>\n",
       "      <td>0.242207</td>\n",
       "      <td>0.209621</td>\n",
       "      <td>0.064868</td>\n",
       "      <td>0.072154</td>\n",
       "      <td>0.629457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.515892</td>\n",
       "      <td>-0.120781</td>\n",
       "      <td>-0.106512</td>\n",
       "      <td>-0.260192</td>\n",
       "      <td>0.197666</td>\n",
       "      <td>-0.155029</td>\n",
       "      <td>-0.306803</td>\n",
       "      <td>0.694974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.047770</td>\n",
       "      <td>-0.230509</td>\n",
       "      <td>0.132355</td>\n",
       "      <td>0.174913</td>\n",
       "      <td>0.242040</td>\n",
       "      <td>-0.229259</td>\n",
       "      <td>-0.835945</td>\n",
       "      <td>0.294148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.574353</td>\n",
       "      <td>-0.132517</td>\n",
       "      <td>-0.091610</td>\n",
       "      <td>0.466463</td>\n",
       "      <td>0.510980</td>\n",
       "      <td>-0.338480</td>\n",
       "      <td>0.202040</td>\n",
       "      <td>-0.100443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment  dimension1  dimension2  dimension3  dimension4  dimension5  \\\n",
       "0          1   -0.400418    0.293417   -0.572702    0.125659    0.471714   \n",
       "1          1   -0.454608   -0.194998   -0.497063    0.242207    0.209621   \n",
       "2          0   -0.515892   -0.120781   -0.106512   -0.260192    0.197666   \n",
       "3          1    0.047770   -0.230509    0.132355    0.174913    0.242040   \n",
       "4          0   -0.574353   -0.132517   -0.091610    0.466463    0.510980   \n",
       "\n",
       "   dimension6  dimension7  dimension8  \n",
       "0   -0.034476    0.042176   -0.429317  \n",
       "1    0.064868    0.072154    0.629457  \n",
       "2   -0.155029   -0.306803    0.694974  \n",
       "3   -0.229259   -0.835945    0.294148  \n",
       "4   -0.338480    0.202040   -0.100443  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 55524 entries, 0 to 55523\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   sentiment   55524 non-null  int64  \n",
      " 1   dimension1  55524 non-null  float64\n",
      " 2   dimension2  55524 non-null  float64\n",
      " 3   dimension3  55524 non-null  float64\n",
      " 4   dimension4  55524 non-null  float64\n",
      " 5   dimension5  55524 non-null  float64\n",
      " 6   dimension6  55524 non-null  float64\n",
      " 7   dimension7  55524 non-null  float64\n",
      " 8   dimension8  55524 non-null  float64\n",
      "dtypes: float64(8), int64(1)\n",
      "memory usage: 3.8 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55524, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>dimension1</th>\n",
       "      <th>dimension2</th>\n",
       "      <th>dimension3</th>\n",
       "      <th>dimension4</th>\n",
       "      <th>dimension5</th>\n",
       "      <th>dimension6</th>\n",
       "      <th>dimension7</th>\n",
       "      <th>dimension8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.400418</td>\n",
       "      <td>0.293417</td>\n",
       "      <td>-0.572702</td>\n",
       "      <td>0.125659</td>\n",
       "      <td>0.471714</td>\n",
       "      <td>-0.034476</td>\n",
       "      <td>0.042176</td>\n",
       "      <td>-0.429317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.454608</td>\n",
       "      <td>-0.194998</td>\n",
       "      <td>-0.497063</td>\n",
       "      <td>0.242207</td>\n",
       "      <td>0.209621</td>\n",
       "      <td>0.064868</td>\n",
       "      <td>0.072154</td>\n",
       "      <td>0.629457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.515892</td>\n",
       "      <td>-0.120781</td>\n",
       "      <td>-0.106512</td>\n",
       "      <td>-0.260192</td>\n",
       "      <td>0.197666</td>\n",
       "      <td>-0.155029</td>\n",
       "      <td>-0.306803</td>\n",
       "      <td>0.694974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.047770</td>\n",
       "      <td>-0.230509</td>\n",
       "      <td>0.132355</td>\n",
       "      <td>0.174913</td>\n",
       "      <td>0.242040</td>\n",
       "      <td>-0.229259</td>\n",
       "      <td>-0.835945</td>\n",
       "      <td>0.294148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.574353</td>\n",
       "      <td>-0.132517</td>\n",
       "      <td>-0.091610</td>\n",
       "      <td>0.466463</td>\n",
       "      <td>0.510980</td>\n",
       "      <td>-0.338480</td>\n",
       "      <td>0.202040</td>\n",
       "      <td>-0.100443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55519</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.349226</td>\n",
       "      <td>-0.236151</td>\n",
       "      <td>0.256277</td>\n",
       "      <td>-0.167399</td>\n",
       "      <td>0.641524</td>\n",
       "      <td>0.501288</td>\n",
       "      <td>-0.230371</td>\n",
       "      <td>-0.112517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55520</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.194372</td>\n",
       "      <td>0.017959</td>\n",
       "      <td>-0.743399</td>\n",
       "      <td>0.242821</td>\n",
       "      <td>0.271741</td>\n",
       "      <td>-0.509180</td>\n",
       "      <td>0.124537</td>\n",
       "      <td>0.040954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55521</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.309441</td>\n",
       "      <td>-0.311137</td>\n",
       "      <td>-0.066972</td>\n",
       "      <td>0.175950</td>\n",
       "      <td>0.684461</td>\n",
       "      <td>0.503490</td>\n",
       "      <td>-0.057506</td>\n",
       "      <td>-0.216101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55522</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.459892</td>\n",
       "      <td>0.036321</td>\n",
       "      <td>-0.695212</td>\n",
       "      <td>-0.030716</td>\n",
       "      <td>0.374198</td>\n",
       "      <td>-0.347496</td>\n",
       "      <td>0.013221</td>\n",
       "      <td>0.204852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55523</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.162520</td>\n",
       "      <td>0.600662</td>\n",
       "      <td>-0.050728</td>\n",
       "      <td>0.286591</td>\n",
       "      <td>0.645155</td>\n",
       "      <td>-0.230822</td>\n",
       "      <td>-0.220945</td>\n",
       "      <td>-0.098814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55524 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment  dimension1  dimension2  dimension3  dimension4  dimension5  \\\n",
       "0            1.0   -0.400418    0.293417   -0.572702    0.125659    0.471714   \n",
       "1            1.0   -0.454608   -0.194998   -0.497063    0.242207    0.209621   \n",
       "2            0.0   -0.515892   -0.120781   -0.106512   -0.260192    0.197666   \n",
       "3            1.0    0.047770   -0.230509    0.132355    0.174913    0.242040   \n",
       "4            0.0   -0.574353   -0.132517   -0.091610    0.466463    0.510980   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "55519        0.0    0.349226   -0.236151    0.256277   -0.167399    0.641524   \n",
       "55520        1.0    0.194372    0.017959   -0.743399    0.242821    0.271741   \n",
       "55521        0.0    0.309441   -0.311137   -0.066972    0.175950    0.684461   \n",
       "55522        0.0   -0.459892    0.036321   -0.695212   -0.030716    0.374198   \n",
       "55523        1.0   -0.162520    0.600662   -0.050728    0.286591    0.645155   \n",
       "\n",
       "       dimension6  dimension7  dimension8  \n",
       "0       -0.034476    0.042176   -0.429317  \n",
       "1        0.064868    0.072154    0.629457  \n",
       "2       -0.155029   -0.306803    0.694974  \n",
       "3       -0.229259   -0.835945    0.294148  \n",
       "4       -0.338480    0.202040   -0.100443  \n",
       "...           ...         ...         ...  \n",
       "55519    0.501288   -0.230371   -0.112517  \n",
       "55520   -0.509180    0.124537    0.040954  \n",
       "55521    0.503490   -0.057506   -0.216101  \n",
       "55522   -0.347496    0.013221    0.204852  \n",
       "55523   -0.230822   -0.220945   -0.098814  \n",
       "\n",
       "[55524 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocess Data\n",
    "\n",
    "Your task is to predict the score of the sentiment (positive or negative) between 0 and 1 based on the embeddings of the tweets specified in columns 2 – 9 of the pre-possessed spreadsheet (or the original tweets if you decided to work with the raw tweeting data). To evaluate the performance of your model, please split the dataset into the train set and the test set in the 0.8:0.2 ratio and use cross-validation to calculate the prediction performance.\n",
    "\n",
    "## 2.1 Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'sentiment'\n",
    "\n",
    "data = data.astype('float32')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(target, axis=1), # predictors\n",
    "    data[target], # target\n",
    "    test_size=0.2,\n",
    "    random_state=90\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44419, 8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11105, 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_splits = KFold(n_splits=5, random_state=90, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #1: Train shape: (35535, 8), Test shape: (8884, 8)\n",
      "Fold #2: Train shape: (35535, 8), Test shape: (8884, 8)\n",
      "Fold #3: Train shape: (35535, 8), Test shape: (8884, 8)\n",
      "Fold #4: Train shape: (35535, 8), Test shape: (8884, 8)\n",
      "Fold #5: Train shape: (35536, 8), Test shape: (8883, 8)\n"
     ]
    }
   ],
   "source": [
    "fold_num = 1\n",
    "for train, test in cv_splits.split(X_train, y_train):\n",
    "    print(f'Fold #{fold_num}: Train shape: {X_train.iloc[train].shape}, Test shape: {X_train.iloc[test].shape}')\n",
    "    fold_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_grid_search(model):\n",
    "    \n",
    "    param_grid = {\n",
    "        'epochs': [50],\n",
    "        'batch_size':[25, 50, 100, 250, 500]\n",
    "    }\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        n_jobs=-1,\n",
    "        cv=cv_splits\n",
    "    )\n",
    "\n",
    "    grid_result = grid.fit(X_train, y_train)\n",
    "    \n",
    "    # summarize results\n",
    "    print(f\"Best: {-grid_result.best_score_:.4f} using {grid_result.best_params_:}\")\n",
    "    means = -grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(f\"{mean:.4f} +/- {stdev:.4f} with: {param}\")\n",
    "    \n",
    "    return grid_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Neural Networks\n",
    "\n",
    "You can use any neural network model you like for this classification task. In particular, you may start with a simple single fully connected network as a “baseline” and then try to use more complex models, including CNN and RNN based models, to achieve better performance results than this simple baseline model.  Your goal is to reach the mean absolute error of at least 0.48, which should not be too difficult. If you want to be more ambitious, you can try to reach the mean absolute error of 0.47 (medium difficulty), or even 0.46 (this is difficult). The higher accuracy you get, the more points you will be awarded. \n",
    "\n",
    "In addition to the simple NN baseline mentioned above, you should also build another basic baseline, such as a logistic regression model (similar to the one we used in the RapidMiner Lab done in the class) and compare the performance results of your DL-based model with that baseline. The expectation is that the more sophisticated DL-model should outperform simple baselines.\n",
    "\n",
    "## 3.1 Baseline Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression MAE: 0.4366 +/- 0.0041\n",
      "\n",
      "CPU times: user 639 ms, sys: 98.3 ms, total: 737 ms\n",
      "Wall time: 214 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_lr = LogisticRegression()\n",
    "cv_results_lr = cross_validate(model_lr, X_train, y_train, scoring='neg_mean_absolute_error', cv=cv_splits)\n",
    "cv_lr_mu = -cv_results_lr['test_score'].mean()\n",
    "cv_lr_sd = cv_results_lr['test_score'].std()\n",
    "\n",
    "print(f'Logistic Regression MAE: {cv_lr_mu:.4f} +/- {cv_lr_sd:.4f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MAE: 0.4177 +/- 0.0050\n",
      "\n",
      "CPU times: user 3min 31s, sys: 2.05 s, total: 3min 33s\n",
      "Wall time: 3min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_rf = RandomForestClassifier(n_estimators=500)\n",
    "cv_results_rf = cross_validate(model_rf, X_train, y_train, scoring='neg_mean_absolute_error', cv=cv_splits)\n",
    "cv_rf_mu = -cv_results_rf['test_score'].mean()\n",
    "cv_rf_sd = cv_results_rf['test_score'].std()\n",
    "\n",
    "print(f'Random Forest MAE: {cv_rf_mu:.4f} +/- {cv_rf_sd:.4f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.3 Simple Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.4428 using {'batch_size': 500, 'epochs': 50}\n",
      "0.4621 +/- 0.0189 with: {'batch_size': 25, 'epochs': 50}\n",
      "0.4531 +/- 0.0226 with: {'batch_size': 50, 'epochs': 50}\n",
      "0.4616 +/- 0.0209 with: {'batch_size': 100, 'epochs': 50}\n",
      "0.4524 +/- 0.0247 with: {'batch_size': 250, 'epochs': 50}\n",
      "0.4428 +/- 0.0218 with: {'batch_size': 500, 'epochs': 50}\n",
      "CPU times: user 3.54 s, sys: 751 ms, total: 4.29 s\n",
      "Wall time: 2min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def create_model_nn0():\n",
    "    \n",
    "    # model configuration\n",
    "    loss_function = tf_mae\n",
    "    optimizer = Adam()\n",
    "    \n",
    "    model = Sequential([\n",
    "        Dense(32, activation='relu', input_dim=8),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(loss=loss_function,\n",
    "                  optimizer=optimizer)\n",
    "    \n",
    "    return model\n",
    " \n",
    "model_nn_0 = KerasClassifier(build_fn=create_model_nn0, verbose=0)\n",
    "cv_results_nn_0 = nn_grid_search(model_nn_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Deep Learning\n",
    "\n",
    "### 4.2.1 DL Model #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.4488 using {'batch_size': 50, 'epochs': 50}\n",
      "0.4629 +/- 0.0151 with: {'batch_size': 25, 'epochs': 50}\n",
      "0.4488 +/- 0.0138 with: {'batch_size': 50, 'epochs': 50}\n",
      "0.4564 +/- 0.0132 with: {'batch_size': 100, 'epochs': 50}\n",
      "0.4556 +/- 0.0163 with: {'batch_size': 250, 'epochs': 50}\n",
      "0.4624 +/- 0.0146 with: {'batch_size': 500, 'epochs': 50}\n",
      "CPU times: user 36.7 s, sys: 6.34 s, total: 43.1 s\n",
      "Wall time: 2min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def create_model_nn1():\n",
    "    \n",
    "    # model configuration\n",
    "    loss_function = tf_mae\n",
    "    optimizer = Adam()\n",
    "    \n",
    "    model = Sequential([\n",
    "        Dense(8, activation='relu', input_dim=8),\n",
    "        Dense(8, activation='relu'),\n",
    "        Dense(8, activation='relu'),\n",
    "        Dense(8, activation='relu'),\n",
    "        Dense(8, activation='relu'),\n",
    "        Dense(8, activation='relu'),\n",
    "        Dense(8, activation='relu'),\n",
    "        Dense(8, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(loss=loss_function,\n",
    "                  optimizer=optimizer)\n",
    "    \n",
    "    return model\n",
    " \n",
    "    \n",
    "model_nn_1 = KerasClassifier(build_fn=create_model_nn1, verbose=0)\n",
    "cv_results_nn_1 = nn_grid_search(model_nn_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 DL Model #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.4205 using {'batch_size': 500, 'epochs': 50}\n",
      "0.4256 +/- 0.0047 with: {'batch_size': 25, 'epochs': 50}\n",
      "0.4230 +/- 0.0046 with: {'batch_size': 50, 'epochs': 50}\n",
      "0.4212 +/- 0.0055 with: {'batch_size': 100, 'epochs': 50}\n",
      "0.4217 +/- 0.0057 with: {'batch_size': 250, 'epochs': 50}\n",
      "0.4205 +/- 0.0050 with: {'batch_size': 500, 'epochs': 50}\n",
      "CPU times: user 10.9 s, sys: 1.97 s, total: 12.9 s\n",
      "Wall time: 4min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def create_model_nn2():\n",
    "    \n",
    "    # model configuration\n",
    "    loss_function = tf_mae\n",
    "    optimizer = Adam()\n",
    "    \n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_dim=8),\n",
    "        BatchNormalization(),\n",
    "        Dense(32, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(loss=loss_function,\n",
    "                  optimizer=optimizer)\n",
    "    \n",
    "    return model\n",
    " \n",
    "model_nn_2 = KerasClassifier(build_fn=create_model_nn2, verbose=0)\n",
    "cv_results_nn_2 = nn_grid_search(model_nn_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Evaluation\n",
    "\n",
    "After you build your neural network, apply the trained deep learning model to the test set and evaluate its performance using the accuracy measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DL #2</td>\n",
       "      <td>0.415586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random forest</td>\n",
       "      <td>0.460184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DL #1</td>\n",
       "      <td>0.467447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>simple NN</td>\n",
       "      <td>0.467448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>logistic regression</td>\n",
       "      <td>0.489189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model       MAE\n",
       "0                DL #2  0.415586\n",
       "1        random forest  0.460184\n",
       "2                DL #1  0.467447\n",
       "3            simple NN  0.467448\n",
       "4  logistic regression  0.489189"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # baseline algo predictions\n",
    "preds_lr = model_lr.predict_proba(X_test)[:,1]\n",
    "preds_rf = model_rf.predict_proba(X_test)[:,1]\n",
    "\n",
    "# # # predict test test for NN models\n",
    "preds_nn_0 = cv_results_nn_0.best_estimator_.predict_proba(X_test)[:,1]\n",
    "preds_nn_1 = cv_results_nn_1.best_estimator_.predict_proba(X_test)[:,1]\n",
    "preds_nn_2 = cv_results_nn_2.best_estimator_.predict_proba(X_test)[:,1]\n",
    "\n",
    "# # # evaluation of test predictions\n",
    "mae_test_lr = skl_mae(y_test, preds_lr)\n",
    "mae_test_rf = skl_mae(y_test, preds_rf)\n",
    "mae_test_nn_0 = skl_mae(y_test, preds_nn_0)\n",
    "mae_test_nn_1 = skl_mae(y_test, preds_nn_1)\n",
    "mae_test_nn_2 = skl_mae(y_test, preds_nn_2)\n",
    "\n",
    "test_results_df = pd.DataFrame({\n",
    "    'Model': ['logistic regression', 'random forest', 'simple NN', 'DL #1', 'DL #2'],\n",
    "    'MAE': [mae_test_lr, mae_test_rf, mae_test_nn_0, mae_test_nn_1, mae_test_nn_2]\n",
    "}).sort_values('MAE').reset_index(drop=True)\n",
    "\n",
    "test_results_df"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Bryan Clark"
   },
   {
    "name": "Vamsi Ponnapalli"
   }
  ],
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "title": "Final Project",
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
